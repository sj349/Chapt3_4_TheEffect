---
title: "Chapter 14"
author: "Steph Jordan"
output:
  html_document:
    df_print: paged
---

## Question 1

A. Totals by treatment vs control: 1) control: 10/100 left-handed, 2/100 ambidextrous, 88/100 right-handed, 2) treatment: 6/100 left-handed, 4/100 ambidextrous, 90/100 right-handed.  

Weights for left-handed people in control group: 3/5; weights for right-handed people in control group: 90/88; weights for ambidextrous people in control group: 2

B. Weights for left-handed people in treatment group: 5/3; weights for right-handed people in treatment group: 88/90; weights for ambidextrous people in treatment group: 1/2

C. Using weights from part B to calculate the proportion of left-handed, right-handed, and ambidextrous people in the treatment group:

Left-handed: 

$$(5/3)*(6/100)=10/100$$

right-handed: 
$$(88/90)*(90/100)=88/100 $$
ambidextrous: 

$$(1/2)*(4/100)=2/100 $$

D. Weighted average penmanship score in treated group:
$$ \frac{(5/3)*(7)+(88/90)*6+(1/2)*4)}{(5/3+88/90+1/2)} = 6.21$$
E. Average penmanship among the control group is 5. Therefore, the effect of practicing cursive that we would estimate using this data is: $$6.21-5=1.21$$

## Question 2

A. kernel matching

B. K-nearest neighbor matching

C. Propensity Score matching

D. Distance matching

## Question 3

A. Option B involves less variation, more bias

B. Option A involves less variation, more bias

C. Option B involves less variation, more bias 

D. Option B involves less variation, more bias



## Question 4

In exact matching, you choose control group matches that exactly match treatment group variables. If your dataset is small, these exact matches might be hard to find, leading to the researcher dropping many treated observations, and a misleading estimatation of the average treatment effect.

## Question 5

1. First, divide all matching variables (high school athleticism, parental income, gender, race, and middle school grades) by their standard deviation. 

2. For each observation in the treatment group (i.e. for each athlete) A, and a given control observation B, calculate the sum of the squares of all the differences between each variable for observation A and B.

3. Take the square root of each of these sums.

4. If the value calculated in step 3 is greater than 0.3, discard B as a match for A. If the value is less than or equal to 0.3, include B as a match for A. Note: since we are calculating with replacement, if B is chosen as a match for A it can still be chosen as a match for another observation.

5. Compare grades between treatment observations and matched control groups. Calculate the difference in means between treatment and control.

## Question 6

It requires that the model used to estimate the propensity score is properly specified. (D)

## Question 7

A. The common support assumption fails for the retail group with 1-5 employees

B. No, because the common support assumption pertains to the presence of a comparable control (untreated) group, but here we are just estimating the average treatment effect on the treated. 

C. Bias could pervade our ATE estimate for businesses of size n=11-20 employees. This is due to the fact that the control group has only one business in it. Therefore the average treatment effect for this group will be heavily influenced by the one business in the control group. 

D. If we drop the members from the 1-5 retail group, then we cannot estimate an average treatment effect for neither the 1-5 group nor the 11-20 group (for reasons mentioned in C above). Therefore, we would only be able to estimate a treatment effect for the 6-10 group. 


## Question 8

A. No, there are not significant differences in either variable at the 95% level. We can tell this from the lack of statistical significance markers in the table. 

B. Aside from assessing whether the difference in means was statistically significant, I would check to see how the difference in means after matching compares to the difference in means prior to matching. I would perform difference of means tests for each of the variables between treatment and control groups, and also evaluate the standardized difference in means. I would also look at the distribution of the variable in treatment and control groups after matching. Similar means across treatment and control groups can be misleading, because they can obscure drastically different distributions of the variable within treatment and control groups. We can identify this by plotting the distribution of the variable in treatment and control groups and seeing how they compare. 

We could also look at the love plots, and see if the differences in standardized mean differences are less than 0.1 across all matching variables. 

C. The matching process is supposed to be iterative, so if we find that the balance is bad after the first round of matching, we can change some part of the matching procedure (add more variables, choose a different propensity score model, different bandwidth, etc) and re-do the matching process.

## Question 9

If we are matching on the treated group, then we are choosing untreated counterparts based on their similarity to the treated group. Thus, we are trying to develop the counterfactual based on the fact that one group has already received treatment, and we end up identifying the ATT. Conversely, when we are matching on the untreated group, then we are trying to create a reverse-counterfactual, and we end up choosing treated counterparts based on their similarity to the untreated group. Thus the values we end up selecting based on are those of the untreated group, and we estimate the ATUT.



## Coding section

## Question 1

```{r}
library(MatchIt)
library(WeightIt)
library(cobalt)
library(tidyverse)
library(broom)
library(haven)
library(vtable)
```


Load the `nsw_mixtape` data that can be found in the **causaldata** package associated with the book, or download it fromLoad the `dengue.csv` file provided to you, or from [this site](https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nsw_mixtape.csv). Documentation on the variables is available through the package, or [here](https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/nsw_mixtape.html).

Then, drop the `data_id` variable from the data.

*Language-specific instructions*: 

- In R or Python, store the data set as `nsw`.
- In R, after loading the **tidyverse** you can drop using `select(-droppedvariable)`
- In Stata, it's `drop droppedvariable`
- In Python, after loading **pandas** it's `nsw.drop('droppedvariable', axis = 1)


Loading data
```{r}
nsw <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nsw_mixtape.csv")
```


```{r}
nsw <- nsw|>dplyr::select(-'data_id')
```



## Question 2A

Let's see where we're at before we do any matching at all. `nsw_mixtape` is from an experiment (read that documentation!) so that should already put us in a pretty good place.
First, create a variable called `weight` in your data equal to 1 for all observations (weights that are all 1 will have no effect, but this will give us a clue as to how we could incorporate matching weights easily).
Second, write code that uses a set of given weights to estimate the effect of `treat` on `re78`, using `weight` as weights, and prints out a summary of the regression results. The easiest way to do this is probably weighted regression; see The Effect Section 13.4.1, but without any controls or predictors other than `treat`. **Keep in mind the standard errors on the estimate won't be quite right, since they won't account for the uncertainty in creating the weights.**
Third, write code that creates and prints out a weighted balance table for all variables across values of `treat`, using `weight` as weighted. See The Effect Section 14.6.3. Don't worry about getting a table with tests of significant differences for now; just the means. 
*Language-specific instructions*:



```{r}
nsw$weight <- 1
```

```{r}
# Add the weights argument to lm
m1 <- lm(re78 ~ treat, 
         data = nsw,
         weights = weight)

tidy(m1, conf.int = TRUE)
```


```{r}
sumtable(nsw, group='treat', group.weights =  'weight', group.test= TRUE, out='return')
```
## Question 2B

Is there anything potentially concerning about the balance table, given that this is a randomized experiment where `treat` was randomly assigned?

Yes. The difference in means is rather high for some variables, particularly nodegree and hispanic. This implies that there might be open back doors, depsite the attempt for random assignment. 

## Question 3

Using all of the variables in the data except `treat` and `re78` as matching variables, perform 3-nearest-neighbor Mahalanobis distance matching with replacement and no caliper (The Effect 14.4.1) and calculate the post-matching average treatment on the treated effect of `treat` on `re78`.
Check the documentation of the function you use to be sure you're matching with replacement.



```{r}
#do the matching

match1 <- matchit(treat ~ age+educ+black+hisp+marr+nodegree+re74+re75,
                  data = nsw,
                  method = "nearest",
                  distance = "mahalanobis",
                  estimand = "ATT",
                  ratio=3,
                  replace = TRUE)  
```



```{r}
#### get matched data for calculating weighted difference
md1 <- match.data(match1)

#### compute weighted difference (ATT)
matchdiff1 <- lm(re78 ~ treat,
                 data = md1,
                 weights = weights)
tidy(matchdiff1, conf.int = TRUE)
```

The average treatment effect estimate is 2052.319. 

## Question 4

Create a post-matching balance table showing balance for all the matching variables (you'll probably want to use the balance function designed to follow the matching function you used, from the same package). Write a sentence commenting on whether the balance looks good. You may have to read the documentation for the function you use to figure out what the results mean.


Creating balance table

```{r}
#### summary
md1 |> 
  group_by(treat) |> 
  summarize(across(age:re75, ~ weighted.mean(.x, weights)))

```

```{r}
#### cobalt balance checks
love.plot(match1,
          abs = TRUE,
          binary = "std",
          thresholds = .1)
```


The balance is pretty good (most variables are below the 0.1 threshold), but some are not (marriage and nodegree). We could possibly improve balance further by using a CBPS or entropy balancing method. 


## Question 5

Switching over to propensity score matching, use the same matching variables as in Question 3 to estimate the propensity to be treated (with a logit regression), and then add the treatment propensity to the data set as a new variable called `propensity`. Trim the propensity score, setting to missing any values from 0 to .05 or from .95 to 1 (this is a different method than done in the chapter).



```{r}
m2 <- glm(treat ~ age + educ + black + hisp + marr + nodegree + re74 + re75, 
           data = nsw, family = binomial(link = 'logit'))

# Get predicted values
nsw <- nsw |>
    mutate(propensity = predict(m2, type = 'response')) 
```



'Trimming' propensity

```{r}
nsw <- nsw |> mutate(propensity = ifelse(propensity<0.05 | propensity >0.95, NA_real_, propensity))
  
```



## Question 6

Create a new variable in the data called `ipw` with the inverse probability weight, and then estimate the treatment effect using those weights in a linear regression (keeping in mind the standard errors won't be quite right).


```{r}
# Create IPW weights
nsw <- nsw |>
    mutate(ipw = case_when(
    treat == 1 ~ 1/propensity,
    treat == 0 ~ 1/(1-propensity)))
```

```{r}
matchdiff3 <- lm(re78 ~ treat, data = nsw, weights = ipw)
```

```{r}
##why is the coefficient NA)

tidy(matchdiff3, conf.int = TRUE)
```
The estimaed treatment effect is 1641.315.

## Question 7

7. Make a common support graph, overlaying the density of the `propensity` variable for treated observations on top of the density of the `propensity` variable for untreated observations. You may want to refer to [this guide](https://lost-stats.github.io/Presentation/Figures/density_plots.html) if you are not familiar with your language's graphing capabilities.
Write a line commenting on how the common support looks. 

```{r}
ggplot(nsw, aes(x = propensity, color = factor(treat))) +
  geom_density()
```

## Question 8

Use the prepackaged command for inverse probability weighting used in the chapter for your language to estimate the treatment effect. Don't apply a trim (as previously established, for this particular problem it doesn't do much).


```{r, results='hide', warning=FALSE}
library(causalweight)
Y <- nsw %>%
    pull(re78)
# Treatment
D <- nsw %>%
    pull(treat)
# Matching variables
X <- nsw %>%
    dplyr::select(-c('treat', 're78', 'propensity', 'ipw')) %>%
    as.matrix()

# Note by default this produces average treatment effect,
# not average treatment on the treated, and trims propensity 
# scores based on extreme values rather than matching treated range
IPW <- treatweight(Y, D, X, trim = 0, logit = TRUE)

```

```{r}
# Estimate and SE
IPW$effect
IPW$se
```


Estimated treatment effect using 'treatweight' command is 1794.342.

